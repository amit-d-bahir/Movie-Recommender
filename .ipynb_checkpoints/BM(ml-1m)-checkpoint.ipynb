{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Importing the dataset\n",
    "columns = ['Movie_Id', 'Title', 'Genre']\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', names = columns, header = None, engine = 'python', encoding = 'latin-1')\n",
    "\n",
    "cols = ['User_Id', 'Gender', 'Age', 'User_job_code', 'Zip_Code']\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', names = cols, engine = 'python', encoding = 'latin-1')\n",
    "\n",
    "cols1 = ['User_Id', 'Movie_Id', 'Ratings', 'Time_Stamp']\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', names = cols1, engine = 'python', encoding = 'latin-1')\n",
    "\n",
    "# Preparing the training set and the test set\n",
    "training_set = pd.read_csv('ml-1m/training_set.csv')\n",
    "training_set = np.array(training_set)\n",
    "test_set = pd.read_csv('ml-1m/test_set.csv')\n",
    "test_set = np.array(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,       661,         3, 978302109],\n",
       "       [        1,       914,         3, 978301968],\n",
       "       [        1,      3408,         4, 978300275],\n",
       "       ...,\n",
       "       [     6040,       562,         5, 956704746],\n",
       "       [     6040,      1096,         4, 956715648],\n",
       "       [     6040,      1097,         4, 956715569]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the number of users and movies\n",
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users, nb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into an array with users in lines and movies in columns\n",
    "\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users] # or data[data[:,0] == id_users, 1]\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "        if (id_users == 2):\n",
    "            print(id_movies)\n",
    "            print(id_ratings)\n",
    "            print(ratings)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1357 1537  647  648 2268 2628 2916 3468 1210 1792 1687 3578 1217 3105\n",
      " 3107 3108 3035 1610  292 2236 3071  902  368 1259 3147 1544 1293 3256\n",
      " 3257  110 2278 2490 1834 3471 1690 3654 2852 1945  982 2858 1225 2028\n",
      "  515  442 2312  265 1408 1084  480 2067 1370 1193 1801 1372 2353 3334\n",
      " 2427  590 1196 1552 1198  593 2571 1917 2396 3735 1953 1597 3809 1955\n",
      "  235 1124 1957  163   21  165 2321 1090 2501  349  457  920  459 1527\n",
      " 3418 3095  780  498 2728 2002 2943 2006  318 1207 1244 3893 1247]\n",
      "[5 4 3 4 5 3 3 5 4 3 3 5 3 4 2 3 4 5 3 5 4 2 4 5 5 4 5 2 3 5 3 3 4 5 3 3 3\n",
      " 5 4 4 5 4 5 3 3 4 3 3 5 5 5 5 3 3 4 4 2 5 5 3 4 5 4 3 4 3 4 3 3 4 3 5 5 4\n",
      " 1 3 3 2 5 4 4 5 3 4 4 4 3 3 3 5 4 3 5 4 3 1 5]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[3068 2194 1103 1213 2881 3030  434 2126 1253 1188 3255  589 1873 3699\n",
      " 1442 1265  736 2359   95 2717 1954  380 1096 1385 3451 1962 1784 1968\n",
      " 3678  356 1245 1246]\n",
      "[4 4 3 2 3 4 2 3 3 4 4 4 4 2 4 3 4 3 2 3 5 5 4 3 4 5 5 2 3 5 2 5]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set) # the argument should always be a list of lists\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6040, 3952])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the ratings into Binary ratings 1(Liked) and 0(Not Liked)\n",
    "training_set[training_set == 0] = -1  #all those movies that were not reviewed\n",
    "training_set[training_set == 1] = 0   #movies Not Liked\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1   #movies Liked\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the architecture of the Neural Network\n",
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        # nv -> number of visible nodes\n",
    "        #nh -> number of hidden nodes\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        #weights are all the parameters of the probabilites of the visible nodes given the hidden nodes\n",
    "        #initialises a tensor of size as specified according to a Normal Distribution\n",
    "        \n",
    "        self.a = torch.randn(1, nh) \n",
    "        # 1 creates a 2D tensor -->> bcoz the torch functions do not accept a single input vector\n",
    "        #probabilites of hidden nodes given the visible nodes\n",
    "        \n",
    "        self.b = torch.randn(1, nv)\n",
    "        #probabilites of visible nodes given the hidden nodes\n",
    "        \n",
    "    #Functions for Gibbs Sampling\n",
    "    def sample_h(self, x):\n",
    "        #x -> number of visible neurons\n",
    "        # we have to calculate the probability of h(hidden nodes) given v(visible nodes)\n",
    "        #This is nothing but the sigmoid function applies to Wx + a(bias)\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)  \n",
    "        #as input vector is treated in batches, so to ensure it is apllied to each line of mini batch\n",
    "        #probability that hidden node is activated given the visible node\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    def sample_v(self, y):\n",
    "        #y -> hidden nodes\n",
    "        #probability of v given h\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "    #Contrastive Divergence\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our RBM Object\n",
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: tensor(0.2428)\n",
      "epoch: 2  loss: tensor(0.2283)\n",
      "epoch: 3  loss: tensor(0.2279)\n",
      "epoch: 4  loss: tensor(0.2284)\n",
      "epoch: 5  loss: tensor(0.2283)\n",
      "epoch: 6  loss: tensor(0.2277)\n",
      "epoch: 7  loss: tensor(0.2284)\n",
      "epoch: 8  loss: tensor(0.2280)\n",
      "epoch: 9  loss: tensor(0.2279)\n",
      "epoch: 10  loss: tensor(0.2279)\n"
     ]
    }
   ],
   "source": [
    "# Training the RBM\n",
    "nb_epochs = 10\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.0 # counter\n",
    "    for id_user in range(0, nb_users - batch_size , batch_size):\n",
    "        vk = training_set[id_user : id_user+batch_size]\n",
    "        v0 = training_set[id_user : id_user+batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        s += 1.0\n",
    "    print('epoch: ' + str(epoch) + '  loss: ' + str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : tensor(0.2114)\n"
     ]
    }
   ],
   "source": [
    "# Testing the RBM\n",
    "test_loss = 0\n",
    "s = 0.0\n",
    "\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user : id_user + 1]\n",
    "    vt = test_set[id_user : id_user + 1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.0\n",
    "print('Loss : ' + str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
